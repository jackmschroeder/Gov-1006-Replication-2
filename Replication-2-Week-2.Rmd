---
title: 'Replication #2'
author: "Jack Schroeder"
date: "2/18/2019"
output:
  html_document: default
citation_package: natbib
bibliography: bibliography.bib
---

## Abstract

I replicate "Causal effect of intergroup contact on exclusionary attitudes" (@enos2014) using code/data deposited in the Harvard Dataverse (@DVN/DOP4UB_2017). I replicate Tables 1 and 2 using the `gt` package. I then extend Enos' work by modeling his results using logistic regression (which required recoding poll responses). My use of `gt` prevented me from knitting as a pdf, so my submission is in html format.  

Great abstract

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Begin by calling for Enos' libraries.

library(stargazer)
library(tidyverse)
library(ri)
library(RItools)
library(data.table)
library(gt)

# Enos had this in to set scientific notation.

options(scipen = 999)  

# I load in dat.all, which is the only part of Enos' code I need.

dat.all <- read.csv('Enos Code/pnas_data.csv')

```

```{r, echo=FALSE}
# I like the idea of using logistic regression to analyze Enos' results.
# To do so, I need to add a column to dat.all that equals 1 if the 
# respondent became more conservative and a 0 if there was no change or
# if the respondent became more liberal. I think coding no change as a 0
# rather than a 1 will make any statistically significant results more
# robust and help avoid a Type I error.

# Excellent commenting, and yes, I agree with the coding scheme

dat.all <- dat.all %>% 
  mutate(Remain.b = case_when((Remain.y-Remain.x) > 0 ~ 1,
                              TRUE ~ 0),
         numberim.b = case_when((numberim.y - numberim.x) > 0 ~ 1,
                                TRUE ~ 0),
         Englishlan.b = case_when((Englishlan.y - Englishlan.x) > 0 ~ 1,
                                  TRUE ~ 0),
         
# I also create an overall column that is coded 1 if the respondent had
# a net conservative shift, and a 0 if otherwise.

         Overall.b = case_when((Remain.y + numberim.y + Englishlan.y) - 
                                 (Remain.x + numberim.x + Englishlan.x) > 
                                 0 ~ 1,
                               TRUE ~ 0))
```

```{r main results, echo=FALSE}

# This code chunk is here to create Table 1. The first 
# thing Enos does is create the vectors for each question
# that was asked. He also assigns x.names, y.names, and 
# covariates, but I am not sure what their purposes are.

repeats <- c("numberim","Remain","Englishlan")
x.names <- paste(repeats,".x",sep="")
y.names <- paste(repeats,".y",sep="")
b.names <- paste(repeats,".b",sep="")
covariates <- c('line.x')


# Enos makes the matrix that will include the final results.

final.mat <- matrix(nrow = 0, ncol = 10)

# These vectors will subset the data by waiting preference.

subsets <- c('all','no.car')

# The for loop here is taking the subsets created above
# (all and no.car) and creating the conditions to make
# Table 1.

for(subset in subsets){

	out.mat = matrix(nrow = length(repeats), ncol = 10)
	
# Looking at all respondents.
	
	if(subset == 'all'){
		dat.subset = dat.all
	}
	
# Essentially filtering out respondents who wait in their
# cars (we want people waiting on a platform to hear the
# confederates speak Spanish).
	
	if(subset ==  'no.car'){
		dat.subset = dat.all[dat.all$habits != 1,]
		}

# I am not sure what a z-variable is here.
	
	z.variable = 'treatment'

# Another for loop within this for loop. This one looks at
# repeats, which was created above, and subsets the data
# accordingly. This is to distinguish by question. Then
# the loop presumably looks at the Average Treatment
# Effects, along with the Conditional Average Treatment
# Effects of each question.
	
	for(j in 1:length(repeats)){
		dat.subset$x.new = (as.numeric(dat.subset[,x.names[j]])-1)/4  

# The -1 and /4 rescale x to 0-1. The same is done for y. Why is
# this done? The responses to the three questions were given on
# a five-point scale, which when one is subtracted and then 
# the result is divided by 4, yields a scaled answer.
		
		dat.subset$y.new = (as.numeric(dat.subset[,y.names[j]])-1)/4
		
# I found it easier to just modify Enos' original for loop and add
# the new binary into the mix.
		
		dat.subset$b.new = as.numeric(dat.subset[,b.names[j]])
		dat.subset$Y = dat.subset$y.new - dat.subset$x.new
		
		dat.use = dat.subset[is.na(dat.subset$Y) == F,]

# The means and standard deviations of x.new and y.new are found
# (disregarding NA values, of course).
		
		x.sd = sd(dat.use$x.new,na.rm = T)
		x.mean = mean(dat.use$x.new,na.rm = T)
		y.mean = mean(dat.use$y.new,na.rm = T)
		b.sd = sd(dat.use$b.new, na.rm=T)
		b.mean = mean(dat.use$b.new, na.rm = T)

# Not entirely sure what this line does.
		
		y.treat = mean(dat.use$y.new[dat.use$treatment==1],na.rm = T)

# Enos then creates the tables that will be used to help
# create Table 1. It is a treatment table that focuses on stations
# since some stations were control and others were treatment.
		
		station.treatment.table = table(dat.use$station,dat.use[,z.variable])
		no.control.stations = names(which(station.treatment.table[,1] == 0))
		no.treatment.stations = names(which(station.treatment.table[,2] == 0))
		dat.use = dat.use[!dat.use$station%in%c(no.control.stations,no.treatment.stations),]
				
# Assuming that making each station a factor makes the vector 
# easier to work with.
		
		dat.use$station = factor(dat.use$station)
		dat.use$treated_unit = factor(dat.use$treated_unit)
		Xs = data.matrix(dat.use[,covariates])
		
		perms <- genperms(Z = dat.use[,z.variable], blockvar=dat.use$station, clustvar=dat.use$treated_unit)
		probs = genprobexact(Z = dat.use[,z.variable], blockvar=dat.use$station, clustvar=dat.use$treated_unit)

# Enos finds the Average Treatment Effects here. I'm not really
# sure how this is done (what is estate?). Would love to learn
# more about this in class.

# it is really great to have comments like this, I very much appreciate their presence throughout the file
		
		ate = estate(Y = dat.use$Y, Z = dat.use[,z.variable], X = Xs, prob = probs)
		Ys = genouts(Y = dat.use$Y, Z = dat.use[,z.variable], ate = 0)

# Is gendist gender? Distance? 
# generate distribution

		distout <- gendist(Ys,perms, prob=probs)
		disp =	dispdist(distout, ate = ate, display.plot = F)

# Also unfamiliar with the usage of j.
# It indexes just like i, you can use any letter or word really, but i is the convention
# then when you have nested for loops j is usually next
		
		out.mat[j,1] = repeats[j]
		out.mat[j,2] = subset
		out.mat[j,3] = nrow(dat.use)
		out.mat[j,4] = ate
		out.mat[j,5] = disp$greater.p.value
		out.mat[j,6] = disp$lesser.p.value
		out.mat[j,7] = x.sd
		out.mat[j,8] = x.mean
		out.mat[j,9] = b.sd
		out.mat[j,10] = b.mean
	}
	
# Enos just binds together the two matrices.
	
	final.mat = rbind(final.mat,out.mat)
}

# And makes them into a data frame, to which he adds
# column names.

final.mat <- as.data.frame(final.mat)
colnames(final.mat) <- c('variable','subset','N','ate','greater.p.value','lesser.p.value','x.sd','x.mean', 'b.sd', 'b.mean')

# He reassigns this data frame for later use.

final.mat.main <- final.mat
```
## Tables 1 and 2
```{r, echo=FALSE}
# Preceptor's code from last week inspires me to change these factors into numerics.

final.mat.main$ate    <- as.numeric(as.character(final.mat.main$ate)) 
final.mat.main$N      <- as.numeric(as.character(final.mat.main$N)) 
final.mat.main$x.mean <- as.numeric(as.character(final.mat.main$x.mean)) 
final.mat.main$x.sd   <- as.numeric(as.character(final.mat.main$x.sd)) 
final.mat.main$greater.p.value <- as.numeric(as.character(final.mat.main$greater.p.value)) 
final.mat.main$b.sd <- as.numeric(as.character(final.mat.main$b.sd))
final.mat.main$b.mean <- as.numeric(as.character(final.mat.main$b.mean))

# I wasn't familiar with gt at all before this, but Jack Luby's code was helpful in getting
# me oriented. tab_header for titles, tab_source_note for notes/captions.

final.mat.main %>%
  gt() %>%
  tab_header(title = md("Table 1. Experiment Results")) %>%
  tab_source_note("In the first 'All respondents' column, ATE represents responses in T2-T1 for the treatment group compared with the countrol group for the entire experimental sample. Positive values mean a more politically conservative response. In the 'Waits on platform' column, CATEs are the Conditional Average Treatment Effects fro persons who said they stand on the platform, rather than wait in their cars. In the second 'All respondents' column, T1 levels and SDs for each variable for all respondents. All variables scaled 0-1.") %>%
   tab_source_note("*P values from a one-tailed test against the Null Hypothesis of no effect are in parentheses.") %>%
   tab_source_note("‚Å±Each of the questions allowed responses on a five-point scale ranging from strongly agree to strongly disagree (exact answers were changed to be appropriate to the actual question)")
   
   # Really nice looking table. In the future I would recommend formatting the column headers in a nicer manner
   # also rounding the numbers so they all fit. 
   # Love the footnotes

```

```{r balance test, echo=FALSE}

# Starting with the balance check data. Run the balance checks (with cleaned-up code).

out.balance.test <- xBalance(fmla = treatment ~ liberal + republican + obama.disapprove + ride.everyday + voted.2010 + romney.voter + Hispanics.x + age + residency.new + hispanic.new + college + income.new + male + white, data = dat.all, report = c("std.diffs","z.scores","adj.means"), strata = factor(dat.all$station))

# I found Sean's code pretty helpful in formatting the table in gt.
# I start by making the balance test results into a data frame (table2).
# I then select the variables I need.
# great

table2 <- as.data.frame(out.balance.test) %>% 
  select(results.treatment.0.strat,
         results.treatment.1.strat,
         results.std.diff.strat,
         results.z.strat)

# A package called data.table (called above) allows me to put the rownames
# into their own column. I then rename each of those row names to match the
# paper. Finally, I can rename the columns.

setDT(table2, keep.rownames = TRUE)

table2$rn <- c("Liberal",
               "Republican",
               "Obama Disapprove",
               "Ride MBTA every day",
               "Voted 2010",
               "Romney Voter",
               "Hispanic Threat",
               "Age",
               "Residency Year",
               "Hispanic",
               "College",
               "Income",
               "Male",
               "White")

colnames(table2) <- c("Condition", "Control", "Treatment", "Standard difference", "Z-score")

# Now onto gt. fmt_number lets me choose how many decimals I want to show. tab_header
# gives me a title, and tab_footnote lets me format footnotes. I was pretty lost on gt,
# but using  Sean and Jack Luby's code as a reference really helped me out here.

table2 %>%
  gt() %>%
  fmt_number(columns = c("Control",
                         "Treatment",
                         "Standard difference",
                         "Z-score"),
             decimals = 2) %>%
  tab_header(title = "Table 2. Convariate balance across treatment conditions.") %>%
  tab_footnote(
    footnote = "Mean response values for pretreatment variables accounting for stratification into train stations. All variables are 0 and 1 variables, except for Hispanic threat, which is a seven-point scale indicating how threatening respondents find Hispanics, recoded 0-1; residency, which is measured in years; and income, which is annual income in dollars.",
    locations = cells_data(columns = 1, rows = 1)) %>%
  tab_footnote(
    footnote = "Difference in standardized units",
    locations = cells_column_labels(
      columns = c("Standard difference")))
      
      # again, a very nice looking table, maybe better than the original
```
What happened to the figure?

## Extension
To extend Enos' work, I remodeled his results using logistic regression. I recoded the poll responses into a binary (1 indicating the respondent became more conservative) and ran multiple regressions per question. I finished by running regressions on the overall conservative shift of respondents. One thing of note is that the `t.time` was unclear on which treatment it corresponded to (3-day or 10-day). As a result, in Stargazer output, I kept the `t.time` labels similar to their coded value.  

Great intro/orientation for the reader
```{r logistic models, echo=FALSE, include=FALSE}

# The following glm codes run logistic regressions for each question 
# and then overall. I called for summaries to help myself determine 
# what was significant, but include was set to false to prevent them
# from appearing in the html.

numberim_1 <- glm(numberim.b ~ treatment, data = dat.all, family=binomial)
summary(numberim_1)

numberim_2 <- glm(numberim.b ~ treatment + t.time, data = dat.all, family=binomial)
summary(numberim_2)

numberim_3 <- glm(numberim.b ~ treatment + republican, data = dat.all, family=binomial)
summary(numberim_3)

remain_1 <- glm(Remain.b ~ treatment, data = dat.all, family=binomial)
summary(remain_1)

remain_2 <- glm(Remain.b ~ treatment + t.time, data = dat.all, family=binomial)
summary(remain_2)

remain_3 <- glm(Remain.b ~ treatment + zip.pct.hispanic, data = dat.all, family=binomial)
summary(remain_3)

Englishlan_1 <- glm(Englishlan.b ~ treatment, data = dat.all, family=binomial)
summary(Englishlan_1)

Englishlan_2 <- glm(Englishlan.b ~ treatment + t.time, data = dat.all, family=binomial)
summary(Englishlan_2)

Englishlan_3 <- glm(Englishlan.b ~ treatment + college + romney.voter, data = dat.all, family=binomial)
summary(Englishlan_3)

Overall_1 <- glm(Overall.b ~ treatment, data = dat.all, family=binomial)
summary(Overall_1)

Overall_2 <- glm(Overall.b ~ treatment + t.time + college + zip.pct.hispanic + romney.voter, data = dat.all, family=binomial)
summary(Overall_2)

Overall_3 <- glm(Overall.b ~ treatment + zip.pct.hispanic + romney.voter + male, data = dat.all, family=binomial)
summary(Overall_3)
```
First are the models based on the question of increasing the number of immigrants. We see a conservative shift that is most significant in model 2 (and close to significant in models 1 and 3).  
```{r, echo=FALSE, results = "asis"}

# I call Stargazer for the models focusing on number of immigrants.

stargazer(numberim_1, numberim_2, numberim_3,
          header = TRUE,
          style = "ajps",
          type = "html",
          dep.var.labels = "Number of immigrants be increased?",
          omit.stat = c("f","ser","aic","LL"),
          covariate.labels = c("Treatment", "Treatment Time 2b", "Treatment Time 4a", "Treatment Time 4b", "Republican"),
          digits = 2)
```
Second are the models based on the question of allowing the children of undocumented immigrants to remain in the country. There were no significant results here.  
```{r, echo=FALSE, results = "asis"}

# I call Stargazer for the models focusing on undocumented children.

stargazer(remain_1, remain_2, remain_3,
          header = TRUE,
          style = "ajps",
          type = "html",
          dep.var.labels = "Children of undocumented be allowed to stay?",
          omit.stat = c("f","ser","aic","LL"),
          covariate.labels = c("Treatment", "Treatment Time 2b", "Treatment Time 4a", "Treatment Time 4b", "% Hispanic in Zip Code"),
          digits = 2)
```
Third are the models based on the question regarding English as an official language. This question also did not see significant results.  
```{r, echo=FALSE, results = "asis"}

# I call Stargazer for the models focusing on English's official status.

stargazer(Englishlan_1, Englishlan_2, Englishlan_3,
          header = TRUE,
          style = "ajps",
          type = "html",
          dep.var.labels = "English as official language?",
          omit.stat = c("f","ser","aic","LL"),
          covariate.labels = c("Treatment", "Treatment Time 2b", "Treatment Time 4a", "Treatment Time 4b", "College", "Romney Voter"),
          digits = 2)
	  
	  # great use of GLM and stargazer. Tables look nice and your description makes sure the 
	  # reader does not have to guess what is going on. 
	  # Really nice extension!
```
Finally, I created models based on the overall conservative shift of the respondents. To do this, I created a new variable, `Overall.b`, that added up each respondent's scalar responses from pre-treatment and subtracted that value from the post-treatment value. This was done to judge the treatment effects on respondents who, on net, became more conservative during the period of the study. `treatment` and `romney.voter` approached significance in the models.  
```{r, echo=FALSE, results = "asis"}

# Finally, I call Stargazer for the models focusing on overall effects.

stargazer(Overall_1, Overall_2, Overall_3,
          header = TRUE,
          style = "ajps",
          type = "html",
          dep.var.labels = "Overall conservative shift of respondents",
          omit.stat = c("f","ser","aic","LL"),
          covariate.labels = c("Treatment", "Treatment Time 2b", "Treatment Time 4a", "Treatment Time 4b", "College", "% Hispanic in Zip Code", "Romney Voter", "Male"),
          digits = 2)
```

## Discussion 
  
As a whole, running these models using logistic regression did not match Enos' original results. This may be because I chose the wrong variables to test in my models. It could also be due to the way I recoded the poll responses. It is very possible that logistic regression may not be the best way to analyze the provided data. Either way, with the exception on the question concerning the number of immigrants, the treatment does not appear to have had a large effect on polling preferences.

Great notes for replicated tables. Overall, excellent comments throughout original Enos code.

## References
